{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EliseMalvaoCarlson/Challenge2_Alura_Data_Science_TeleconX_Parte2/blob/main/TelecomX_BR_parte2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RgyMaan04TD"
      },
      "source": [
        "\n",
        "\n",
        "# Challenge - Telecom X - parte 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVkDaWjZQfbx"
      },
      "source": [
        "# üõ†Ô∏è 1 - Prepara√ß√£o dos Dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QmfgtmZQfby"
      },
      "source": [
        "## 1.1 - Extra√ß√£o do Arquivo Tratado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7hNoogLQfbz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dados = pd.read_csv(\"https://raw.githubusercontent.com/EliseMalvaoCarlson/Challeng_TelecomX_parte2_BR/refs/heads/main/dados_tratados.csv\")\n"
      ],
      "metadata": {
        "id": "VT-BvpX2E-C_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OqrYIXq6Qfb0"
      },
      "outputs": [],
      "source": [
        "dados.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJjqvgYSQfb1"
      },
      "source": [
        "## 1.2 - Remo√ß√£o de Colunas Irrelevantes\n",
        "\n",
        "A base de dados importada j√° estava sem a coluna customerID"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MKwsNgrQfb1"
      },
      "source": [
        "## 1.3 - Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# O que √© Encoding?\n",
        "\n",
        "No processamento de dados para machine learning, encoding √© o processo de transformar vari√°veis categ√≥ricas (como ‚Äúg√™nero‚Äù ou ‚Äútipo de contrato‚Äù) em valores num√©ricos que os algoritmos conseguem entender. Modelos como Random Forest ou Regress√£o Log√≠stica n√£o conseguem trabalhar diretamente com texto ‚Äî eles precisam de n√∫meros."
      ],
      "metadata": {
        "id": "8TNSddBpYwqZ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LepkVKkyQfb2"
      },
      "source": [
        "### 1.3.1 - Identificar as colunas categ√≥ricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5cPMB93Qfb2"
      },
      "outputs": [],
      "source": [
        "colunas_categoricas = ['gender', 'Partner', 'Dependents', 'PhoneService',\n",
        "                       'MultipleLines', 'InternetService', 'OnlineSecurity',\n",
        "                       'OnlineBackup', 'DeviceProtection', 'TechSupport',\n",
        "                       'StreamingTV', 'StreamingMovies', 'Contract',\n",
        "                       'PaperlessBilling', 'PaymentMethod']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jleFFm-5Qfb3"
      },
      "source": [
        "### 1.3.2 - Aplicar get_dummies()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**O que √© get_dummies()?**\n",
        "\n",
        "A fun√ß√£o get_dummies() do pandas √© usada para codificar vari√°veis categ√≥ricas em formato num√©rico. Isso √© essencial para que algoritmos de machine learning possam processar essas informa√ß√µes"
      ],
      "metadata": {
        "id": "PGotOysaZnik"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AydsmehAQfb3"
      },
      "outputs": [],
      "source": [
        "# Codifica vari√°veis categ√≥ricas (drop_first=True para evitar multicolinearidade)\n",
        "dados_encoded = pd.get_dummies(dados, columns=colunas_categoricas, drop_first=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7P04ntwNQfb3"
      },
      "source": [
        "### 1.3.3 - Verifica√ß√£o da Propor√ß√£o de Evas√£o"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6upXR-CnQfb3"
      },
      "outputs": [],
      "source": [
        "# Propor√ß√£o de churn\n",
        "y = dados['Churn']\n",
        "proporcao_churn = y.value_counts(normalize=True).round(2) * 100\n",
        "\n",
        "# Impress√£o no console\n",
        "print(\"Propor√ß√£o de clientes:\")\n",
        "print(f\"Ativos (Churn = 0): {proporcao_churn[0]}%\")\n",
        "print(f\"Evadidos (Churn = 1): {proporcao_churn[1]}%\")\n",
        "\n",
        "# Visualiza√ß√£o aprimorada\n",
        "plt.figure(figsize=(6, 4))\n",
        "cores = ['blue', '#F44336']  # verde e vermelho mais suaves\n",
        "proporcao_churn.plot(kind='bar', color=cores)\n",
        "\n",
        "# R√≥tulos e t√≠tulo\n",
        "plt.xticks(ticks=[0, 1], labels=['Ativos', 'Evadidos'], rotation=0)\n",
        "plt.title('Distribui√ß√£o das Classes (Churn)', fontsize=14)\n",
        "plt.ylabel('% de Clientes', fontsize=12)\n",
        "plt.ylim(0, 100)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
        "\n",
        "# Adiciona os valores nas barras\n",
        "for i, valor in enumerate(proporcao_churn):\n",
        "    plt.text(i, valor + 2, f'{valor:.1f}%', ha='center', fontsize=12)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-Pt7r-NQfb4"
      },
      "source": [
        "### 1.3.4 - Balanceamento de Classes (opcional)\n",
        "\n",
        "Seria necess√°rio se a propor√ß√£o de churn for muito baixa, algo como Ativos (Churn = 0): 90% / Evadidos (Churn = 1): 10%, mas como obtivemos valores mais altos, n√£o ser√° necess√°rio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "worvkvkPQfb4"
      },
      "source": [
        "### 1.3.5 - Normaliza√ß√£o ou Padroniza√ß√£o (se necess√°rio)\n",
        "\n",
        "Vamos pular essa etapa porque vamos usar Random Forest agora."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "im49q9HrQfb4"
      },
      "source": [
        "# üéØ 2 - Correla√ß√£o e Sele√ß√£o de Vari√°veis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mRuUoFJQfb5"
      },
      "source": [
        "## 2.1 - An√°lise de Correla√ß√£o - Matriz de Correla√ß√£o entre vari√°veis num√©ricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NICVj4NQfb5"
      },
      "outputs": [],
      "source": [
        "corr = dados_encoded.corr().round(4)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**O que √© .corr()?**\n",
        "\n",
        "A fun√ß√£o .corr() calcula a matriz de correla√ß√£o entre todas as vari√°veis num√©ricas do DataFrame dados_encoded. A correla√ß√£o mede o grau de associa√ß√£o entre duas vari√°veis, com valores que variam de:\n",
        "\n",
        "+1: correla√ß√£o positiva perfeita\n",
        "\n",
        "0: nenhuma correla√ß√£o\n",
        "\n",
        "‚Äì1: correla√ß√£o negativa perfeita\n",
        "\n",
        "**E o .round(4)?**\n",
        "\n",
        "Esse m√©todo arredonda os valores da matriz de correla√ß√£o para quatro casas decimais, facilitando a leitura e a visualiza√ß√£o dos resultados.\n",
        "\n",
        "**Resultado: corr**\n",
        "\n",
        "O objeto corr gerado √© uma tabela quadrada onde cada c√©lula representa a correla√ß√£o entre duas vari√°veis. Por exemplo:\n",
        "\n",
        "corr['Churn']['tenure'] mostra a correla√ß√£o entre tempo de contrato e evas√£o.\n",
        "\n",
        "corr['Churn']['Contract_Two year'] mostra a correla√ß√£o entre contratos bienais e churn.\n",
        "\n"
      ],
      "metadata": {
        "id": "uUGSeiuKaqzH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yaJWgb55Qfb5"
      },
      "outputs": [],
      "source": [
        "corr['Churn'].sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8zQYAiuQfb6"
      },
      "outputs": [],
      "source": [
        "# 1. Correla√ß√µes com 'Churn'\n",
        "corr_churn = corr['Churn'].drop('Churn')\n",
        "\n",
        "# 2. Ordenar por correla√ß√£o absoluta\n",
        "correlacoes_ordenadas = corr_churn.reindex(\n",
        "    corr_churn.abs().sort_values(ascending=False).index\n",
        ")\n",
        "\n",
        "# 3. Obter o limite da 10¬™ maior correla√ß√£o (com empates)\n",
        "top_n = 10\n",
        "limite = correlacoes_ordenadas.abs().unique()[top_n - 1]\n",
        "variaveis_relevantes = correlacoes_ordenadas[correlacoes_ordenadas.abs() >= limite].index.tolist()\n",
        "\n",
        "# 4. Incluir 'Churn' na lista\n",
        "variaveis_plot = ['Churn'] + variaveis_relevantes\n",
        "\n",
        "# 5. Criar submatriz de correla√ß√£o\n",
        "submatriz_corr = corr.loc[variaveis_plot, variaveis_plot]\n",
        "\n",
        "# 6. Plotar heatmap\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(\n",
        "    submatriz_corr,\n",
        "    annot=True,\n",
        "    fmt='.2f',\n",
        "    cmap='coolwarm',\n",
        "    vmin=-1, vmax=1,\n",
        "    linewidths=0.5,\n",
        "    linecolor='gray',\n",
        "    cbar_kws={\"shrink\": 0.8}\n",
        ")\n",
        "plt.title('Submatriz das Maiores Correla√ß√µes com Churn', fontsize=14)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmPmWmcsQfb6"
      },
      "source": [
        "## 2.2 - An√°lises Direcionadas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36CMSU4aQfb7"
      },
      "source": [
        "### 2.2.1 - Tempo de contrato √ó Evas√£o"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'Churn' to categorical for plotting\n",
        "dados['Churn'] = dados['Churn'].astype('category')\n",
        "\n",
        "plt.figure(figsize=(8, 5))  # Tamanho do gr√°fico\n",
        "sns.boxplot(x='Churn', y='tenure', data=dados, hue='Churn', palette={0.0: '#4CAF50', 1.0: '#F44336'}, legend=False)  # Cores personalizadas\n",
        "plt.title('Tempo de Contrato x Churn', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Churn (0 = N√£o, 1 = Sim)', fontsize=12)\n",
        "plt.ylabel('Meses de Contrato', fontsize=12)\n",
        "# Adjust xticks to match categorical values\n",
        "plt.xticks(ticks=[0, 1], labels=['N√£o Evadiu', 'Evadiu'], fontsize=11)\n",
        "plt.yticks(fontsize=10)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "leSDJlovGlnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXLuYTn4Qfb7"
      },
      "source": [
        "### 2.2.2 - Total Gasto √ó Evas√£o"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J5V2FK0dQfb8"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(x='Churn', y='Charges.Total', data=dados)\n",
        "plt.title('Total Gasto x Churn')\n",
        "plt.xlabel('Churn (0 = N√£o, 1 = Sim)')\n",
        "plt.ylabel('Valor Total Gasto')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Caa_rzRQfb8"
      },
      "source": [
        "# ü§ñ 3 - Modelagem Preditiva"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7L08NLUgQfb8"
      },
      "source": [
        "## 3.1 - Separa√ß√£o de dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJz6S2B0Qfb8"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = dados_encoded.drop(columns=['Churn'])  # j√° est√° sem customerID\n",
        "y = dados_encoded['Churn']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ug7mrJ0EQfb9"
      },
      "source": [
        "## 3.2 - Cria√ß√£o de modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHYqiuGKQfb9"
      },
      "source": [
        "### 3.2.1 - Treinamento com Random Forest\n",
        "\n",
        "**O que √© Random Forest?**\n",
        "\n",
        "Random Forest √© um algoritmo de aprendizado supervisionado baseado em √°rvores de decis√£o. Ele cria v√°rias √°rvores (da√≠ o ‚Äúforest‚Äù) e combina suas previs√µes para melhorar a precis√£o e reduzir o risco de overfitting.\n",
        "\n",
        "**O que acontece ap√≥s o treinamento?**\n",
        "\n",
        "O modelo aprende padr√µes nos dados para prever a vari√°vel alvo (Churn). Ele ser√° testado depois com dados novos (X_test) para verificar se consegue generalizar bem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iaUwBUBJQfb9"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "modelo_rf = RandomForestClassifier(random_state=42)\n",
        "modelo_rf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOI1gbuhQfb9"
      },
      "source": [
        "### 3.2.2 - Treinamento com Regress√£o Log√≠stica - etapa 1: Separar vari√°veis num√©ricas para normalizar apenas onde necess√°rio\n",
        "\n",
        "**A Regress√£o Log√≠stica √© um modelo estat√≠stico usado para prever vari√°veis**\n",
        "bin√°rias, como o churn (evas√£o de clientes), que pode ser 0 (permaneceu) ou 1 (evadiu). Ela estima a probabilidade de um evento ocorrer com base nas vari√°veis explicativas.\n",
        "\n",
        "**Etapa 1: Normaliza√ß√£o dos dados**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mz0EHnP1Qfb-"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Identificar colunas num√©ricas\n",
        "numericas = X.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
        "\n",
        "# Normalizar os dados para regress√£o log√≠stica\n",
        "scaler = StandardScaler()\n",
        "X_norm = X.copy()\n",
        "X_norm[numericas] = scaler.fit_transform(X_norm[numericas])\n",
        "\n",
        "# Dividir treino/teste com os dados normalizados\n",
        "Xn_train, Xn_test, yn_train, yn_test = train_test_split(\n",
        "    X_norm, y, test_size=0.3, random_state=42, stratify=y # propor√ß√£o de 70% para treino e 30% para teste\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-8BnzbcQfb-"
      },
      "source": [
        "### 3.2.2 - Treinamento com Regress√£o Log√≠stica - etapa 2: Treinar Regress√£o Log√≠stica com dados normalizados\n",
        "\n",
        "**Os dados normalizados foram divididos em treino e teste:**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04jGSKx8Qfb-"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "modelo_log = LogisticRegression(max_iter=1000, random_state=42)\n",
        "modelo_log.fit(Xn_train, yn_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ncKm6tHQfb_"
      },
      "source": [
        "### 3.2.3 - Justificativa de escolha dos modelos para an√°lise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgrCifQrQfb_"
      },
      "source": [
        "###  Random Forest\n",
        "\n",
        "O modelo **Random Forest** foi adotado como uma abordagem baseada em √°rvores de decis√£o. Por sua natureza, ele √© robusto a vari√°veis com diferentes escalas e tipos, o que elimina a necessidade de normaliza√ß√£o dos dados. Essa caracter√≠stica foi considerada na etapa de pr√©-processamento, onde a padroniza√ß√£o foi propositalmente omitida. Apesar de sua alta capacidade de aprendizado, o modelo apresentou sinais de **overfitting**, com desempenho quase perfeito no treino e queda significativa no teste, o que compromete sua capacidade de generaliza√ß√£o.\n",
        "\n",
        "---\n",
        "\n",
        "###  Regress√£o Log√≠stica\n",
        "\n",
        "A **Regress√£o Log√≠stica** foi escolhida como modelo linear base para prever a evas√£o de clientes. Por ser sens√≠vel √† escala das vari√°veis, foi aplicada a **normaliza√ß√£o com StandardScaler** nas colunas num√©ricas antes do treinamento. Essa escolha se justifica por ser um dos algoritmos mais utilizados em problemas de classifica√ß√£o bin√°ria, como o de churn. Al√©m de ser simples e eficiente, ela fornece **coeficientes interpret√°veis**, permitindo entender o impacto de cada vari√°vel na probabilidade de evas√£o.\n",
        "\n",
        "Embora o modelo ainda n√£o tenha sido explorado em profundidade no curso, sua configura√ß√£o foi feita com base em **refer√™ncias confi√°veis e suporte t√©cnico**, garantindo que os ajustes necess√°rios ‚Äî como normaliza√ß√£o e balanceamento ‚Äî fossem corretamente aplicados.\n",
        "\n",
        "---\n",
        "\n",
        "###  Compara√ß√£o entre os modelos\n",
        "\n",
        "A compara√ß√£o entre Random Forest e Regress√£o Log√≠stica permitiu avaliar o desempenho entre t√©cnicas **n√£o-lineares** e **lineares** no contexto da previs√£o de churn. A Regress√£o Log√≠stica demonstrou maior consist√™ncia entre treino e teste, melhor recall e F1-score, al√©m de ser mais confi√°vel para aplica√ß√£o pr√°tica. J√° o Random Forest, apesar de sua alta acur√°cia no treino, mostrou dificuldade de generaliza√ß√£o, refor√ßando a import√¢ncia de ajustes como o GridSearchCV.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "IVTuT7ZfeQWx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1caHkZhQfb_"
      },
      "source": [
        "## 3.3 - Avalia√ß√£o dos Modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fQsT5JsQfcS"
      },
      "source": [
        "### 3.3.1 - M√©tricas: acur√°cia, precis√£o, recall e F1-score.\n",
        "\n",
        "O que s√£o essas m√©tricas?\n",
        "\n",
        "Essas quatro m√©tricas s√£o usadas para **avaliar o desempenho de modelos de classifica√ß√£o**, especialmente em problemas bin√°rios como o churn (evas√£o de clientes):\n",
        "\n",
        "| M√©trica       | Defini√ß√£o                                                                 | Interpreta√ß√£o pr√°tica no notebook |\n",
        "|---------------|---------------------------------------------------------------------------|-----------------------------------|\n",
        "| **Acur√°cia**  | Propor√ß√£o de previs√µes corretas sobre o total de casos                    | Mede o desempenho geral do modelo |\n",
        "| **Precis√£o**  | Propor√ß√£o de casos previstos como positivos que realmente s√£o positivos   | Indica se o modelo evita falsos positivos |\n",
        "| **Recall**    | Propor√ß√£o de casos positivos que foram corretamente identificados         | Mede a capacidade de detectar clientes que realmente evadiram |\n",
        "| **F1-score**  | M√©dia harm√¥nica entre precis√£o e recall                                   | Equil√≠brio entre acertos e cobertura |\n",
        "\n",
        "---\n",
        "\n",
        "### Como foram aplicadas no notebook?\n",
        "\n",
        "O notebook calculou essas m√©tricas para os dois modelos ‚Äî **Random Forest** e **Regress√£o Log√≠stica** ‚Äî tanto no conjunto de **treino** quanto no de **teste**:\n",
        "\n",
        "```python\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "```\n",
        "\n",
        "As previs√µes foram feitas com `.predict()` e os resultados foram organizados em um `DataFrame` chamado `df_metricas`, arredondado para tr√™s casas decimais.\n",
        "\n",
        "---\n",
        "\n",
        "###  Resultados observados\n",
        "\n",
        "####  Random Forest\n",
        "- **Treino**: Acur√°cia de 0.998, Recall de 0.995 ‚Üí quase perfeito (ind√≠cio de overfitting)\n",
        "- **Teste**: Acur√°cia de 0.784, Recall de 0.494 ‚Üí caiu bastante, errou mais da metade dos churns\n",
        "\n",
        "####  Regress√£o Log√≠stica\n",
        "- **Treino**: Acur√°cia de 0.811, Recall de 0.563 ‚Üí desempenho mais realista\n",
        "- **Teste**: Acur√°cia de 0.798, Recall de 0.545 ‚Üí melhor equil√≠brio e generaliza√ß√£o\n",
        "\n",
        "---\n",
        "\n",
        "###  Conclus√£o\n",
        "\n",
        "Essas m√©tricas permitiram comparar os modelos de forma objetiva. O **Random Forest** teve alta acur√°cia no treino, mas baixo recall no teste, indicando overfitting. J√° a **Regress√£o Log√≠stica** mostrou desempenho mais consistente e maior capacidade de identificar clientes que realmente evadiram ‚Äî o que √© essencial para o objetivo do projeto.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26yZS7x8QfcS"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score\n",
        ")\n",
        "import pandas as pd\n",
        "\n",
        "# Previs√µes dos dois modelos - TESTE\n",
        "y_pred_rf = modelo_rf.predict(X_test)\n",
        "y_pred_log = modelo_log.predict(Xn_test)\n",
        "\n",
        "# Previs√µes dos dois modelos - TREINO\n",
        "y_pred_rf_train = modelo_rf.predict(X_train)\n",
        "y_pred_log_train = modelo_log.predict(Xn_train)\n",
        "\n",
        "# Dicion√°rios com as m√©tricas principais - TESTE\n",
        "metricas_rf_test = {\n",
        "    'Modelo': 'Random Forest - Teste',\n",
        "    'Acur√°cia': accuracy_score(y_test, y_pred_rf),\n",
        "    'Precis√£o': precision_score(y_test, y_pred_rf),\n",
        "    'Recall': recall_score(y_test, y_pred_rf),\n",
        "    'F1-Score': f1_score(y_test, y_pred_rf)\n",
        "}\n",
        "\n",
        "metricas_log_test = {\n",
        "    'Modelo': 'Regress√£o Log√≠stica - Teste',\n",
        "    'Acur√°cia': accuracy_score(yn_test, y_pred_log),\n",
        "    'Precis√£o': precision_score(yn_test, y_pred_log),\n",
        "    'Recall': recall_score(yn_test, y_pred_log),\n",
        "    'F1-Score': f1_score(yn_test, y_pred_log)\n",
        "}\n",
        "\n",
        "\n",
        "# Dicion√°rios com as m√©tricas principais - TREINO\n",
        "metricas_rf_train = {\n",
        "    'Modelo': 'Random Forest - Treino',\n",
        "    'Acur√°cia': accuracy_score(y_train, y_pred_rf_train),\n",
        "    'Precis√£o': precision_score(y_train, y_pred_rf_train),\n",
        "    'Recall': recall_score(y_train, y_pred_rf_train),\n",
        "    'F1-Score': f1_score(y_train, y_pred_rf_train)\n",
        "}\n",
        "\n",
        "metricas_log_train = {\n",
        "    'Modelo': 'Regress√£o Log√≠stica - Treino',\n",
        "    'Acur√°cia': accuracy_score(yn_train, y_pred_log_train),\n",
        "    'Precis√£o': precision_score(yn_train, y_pred_log_train),\n",
        "    'Recall': recall_score(yn_train, y_pred_log_train),\n",
        "    'F1-Score': f1_score(yn_train, y_pred_log_train)\n",
        "}\n",
        "\n",
        "# Criar DataFrame com os dois modelos\n",
        "df_metricas = pd.DataFrame([metricas_rf_test, metricas_log_test, metricas_rf_train, metricas_log_train])\n",
        "df_metricas.set_index('Modelo', inplace=True)\n",
        "df_metricas = df_metricas.round(3)\n",
        "\n",
        "# Mostrar as m√©tricas em tabela\n",
        "print(\"\\nüìä Comparativo das M√©tricas Principais:\")\n",
        "df_metricas\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwZIWJDTQfcT"
      },
      "source": [
        "### 3.3.1 - M√©trica: matriz de confus√£o"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eIdKIHjQfcT"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import pandas as pd\n",
        "\n",
        "# --- Previs√µes para o conjunto de TESTE ---\n",
        "y_pred_rf_test = modelo_rf.predict(X_test)\n",
        "y_pred_log_test = modelo_log.predict(Xn_test)\n",
        "\n",
        "# --- Previs√µes para o conjunto de TREINO ---\n",
        "y_pred_rf_train = modelo_rf.predict(X_train)\n",
        "y_pred_log_train = modelo_log.predict(Xn_train)\n",
        "\n",
        "print(\"--- MATRIZES DE CONFUS√ÉO ---\")\n",
        "\n",
        "# --- Matriz Random Forest - TESTE ---\n",
        "print(\"\\nüìä Matriz de Confus√£o - Random Forest (Teste)\")\n",
        "print(pd.DataFrame(confusion_matrix(y_test, y_pred_rf_test),\n",
        "                   index=['Atual: Permaneceu', 'Atual: Evadiu'],\n",
        "                   columns=['Previsto: Permaneceu', 'Previsto: Evadiu']))\n",
        "\n",
        "# --- Matriz Random Forest - TREINO ---\n",
        "print(\"\\nüìä Matriz de Confus√£o - Random Forest (Treino)\")\n",
        "print(pd.DataFrame(confusion_matrix(y_train, y_pred_rf_train),\n",
        "                   index=['Atual: Permaneceu', 'Atual: Evadiu'],\n",
        "                   columns=['Previsto: Permaneceu', 'Previsto: Evadiu']))\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60 + \"\\n\")  # Divisor maior entre modelos\n",
        "\n",
        "# --- Matriz Regress√£o Log√≠stica - TESTE ---\n",
        "print(\"üìä Matriz de Confus√£o - Regress√£o Log√≠stica (Teste)\")\n",
        "print(pd.DataFrame(confusion_matrix(yn_test, y_pred_log_test),\n",
        "                   index=['Atual: Permaneceu', 'Atual: Evadiu'],\n",
        "                   columns=['Previsto: Permaneceu', 'Previsto: Evadiu']))\n",
        "\n",
        "# --- Matriz Regress√£o Log√≠stica - TREINO ---\n",
        "print(\"\\nüìä Matriz de Confus√£o - Regress√£o Log√≠stica (Treino)\")\n",
        "print(pd.DataFrame(confusion_matrix(yn_train, y_pred_log_train),\n",
        "                   index=['Atual: Permaneceu', 'Atual: Evadiu'],\n",
        "                   columns=['Previsto: Permaneceu', 'Previsto: Evadiu']))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q05aMf6zQfcU"
      },
      "source": [
        "### 3.3.2 - An√°lise cr√≠tica"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omt_-qwXQfcU"
      },
      "source": [
        "## ‚úÖ **Resumo geral das m√©tricas**\n",
        "\n",
        "| Modelo                      | Acur√°cia | Precis√£o | Recall | F1-Score |\n",
        "| --------------------------- | -------- | -------- | ------ | -------- |\n",
        "| **Random Forest - Treino**  | 0.998    | 0.996    | 0.995  | 0.996    |\n",
        "| **Random Forest - Teste**   | 0.784    | 0.617    | 0.494  | 0.549    |\n",
        "| **Reg. Log√≠stica - Treino** | 0.811    | 0.671    | 0.563  | 0.613    |\n",
        "| **Reg. Log√≠stica - Teste**  | 0.798    | 0.640    | 0.545  | 0.589    |\n",
        "\n",
        "---\n",
        "\n",
        "## üîç **An√°lise detalhada por modelo**\n",
        "\n",
        "### üå≤ **Random Forest**\n",
        "\n",
        "#### üü© Ponto positivo:\n",
        "\n",
        "* Acertou 1380 dos 1552 clientes que permaneceram.\n",
        "* Boa precis√£o no teste (0.617), ou seja, quando prev√™ churn, costuma acertar.\n",
        "\n",
        "#### üü• Ponto preocupante:\n",
        "\n",
        "* **Desempenho em treino alt√≠ssimo (quase 100%)** e queda forte no teste.\n",
        "* Recall no teste √© baixo (0.494), ou seja, **erra mais de 50% dos clientes que evadiram**.\n",
        "* Matriz de confus√£o do treino mostra apenas **11 erros em mais de 5000 registros** ‚Äî isso √© um **sinal claro de overfitting**.\n",
        "\n",
        "#### üìâ Conclus√£o:\n",
        "\n",
        "> **Random Forest memorizou os dados de treino** e teve dificuldade de generalizar no conjunto de teste. Apesar de sua alta performance no treino, seu desempenho real √© limitado.\n",
        "\n",
        "---\n",
        "\n",
        "### üìà **Regress√£o Log√≠stica**\n",
        "\n",
        "#### üü© Ponto forte:\n",
        "\n",
        "* Manteve **boa consist√™ncia entre treino e teste** ‚Äî ou seja, generaliza melhor.\n",
        "* No teste:\n",
        "\n",
        "  * **Maior recall (0.545)** ‚Üí identificou mais clientes que realmente evadiram\n",
        "  * **Melhor F1-score (0.589)** ‚Üí equil√≠brio mais robusto entre precis√£o e recall\n",
        "\n",
        "#### üü® Considera√ß√µes:\n",
        "\n",
        "* No treino, teve desempenho inferior ao Random Forest, mas **sem exagero**.\n",
        "* Apresentou 737 acertos de churn e 571 falsos negativos (matriz de confus√£o treino), o que √© **realista para modelos simples e interpret√°veis**.\n",
        "\n",
        "#### üìâ Conclus√£o:\n",
        "\n",
        "> Embora menos potente que Random Forest, a Regress√£o Log√≠stica mostra **desempenho est√°vel, interpret√°vel e mais confi√°vel para aplica√ß√£o pr√°tica.**\n",
        "\n",
        "---\n",
        "\n",
        "## üß† **An√°lise comparativa (cr√≠tica)**\n",
        "\n",
        "| Crit√©rio                  | Random Forest        | Regress√£o Log√≠stica | Melhor modelo |\n",
        "| ------------------------- | -------------------- | ------------------- | ------------- |\n",
        "| Acur√°cia no teste         | 0.784                | **0.798**           | üîπ Log√≠stica  |\n",
        "| Recall (teste - churn)    | 0.494                | **0.545**           | üîπ Log√≠stica  |\n",
        "| F1-Score (teste)          | 0.549                | **0.589**           | üîπ Log√≠stica  |\n",
        "| Consist√™ncia treino/teste | ‚ùå (muito gap)        | ‚úÖ (coerente)        | üîπ Log√≠stica  |\n",
        "| Overfitting detectado?    | ‚úÖ Sim                | ‚ùå N√£o               | üîπ Log√≠stica  |\n",
        "| Facilidade de explica√ß√£o  | M√©dia (import√¢ncias) | Alta (coeficientes) | üîπ Log√≠stica  |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3QogW9YQfcU"
      },
      "source": [
        "### 3.3.3 - Justificativa da escolha do modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkK_T2MeQfcV"
      },
      "source": [
        "Com base nas m√©tricas de desempenho obtidas at√© esta etapa, o modelo de **Regress√£o Log√≠stica** apresentou resultados superiores ao Random Forest em todos os principais indicadores: acur√°cia, precis√£o, recall e F1-score. Destaca-se, sobretudo, o **maior recall**, essencial para a identifica√ß√£o de clientes com risco real de evas√£o ‚Äî objetivo central deste projeto.\n",
        "\n",
        "O modelo **Random Forest**, por sua vez, apesar de apresentar boa performance em teste, demonstrou sinais evidentes de **overfitting**, com desempenho quase perfeito no conjunto de treino. Esse comportamento sugere baixa capacidade de generaliza√ß√£o para novos dados.\n",
        "\n",
        "**Assim, at√© o momento, a Regress√ßao Log√≠stica √© a op√ß√£o mais adequada dentre os modelos treinados inicialmente.**\n",
        "\n",
        "Entretanto, essa an√°lise cr√≠tica abre espa√ßo para poss√≠veis melhorias. Em uma pr√≥xima etapa, ser√° conduzido um **aprofundamento t√©cnico com refinamento dos modelos, visando corrigir distor√ß√µes como overfitting e melhorar a sensibilidade na detec√ß√£o de churn.**\n",
        "\n",
        "Esse processo permitir√° validar se a escolha atual permanece como a mais indicada ou se outro modelo, ap√≥s ajustes, poder√° apresentar desempenho mais robusto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nf6YgSTbQfcV"
      },
      "source": [
        "### 3.3.4 - Overfitting ou Underfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EnJaeSrQfcV"
      },
      "source": [
        "### üîç Random Forest\n",
        "\n",
        "**Conclus√£o:**\n",
        "> Forte ind√≠cio de **Overfitting**.  \n",
        "O modelo Random Forest performou quase perfeitamente nos dados de treino, mas teve **queda significativa** no teste. Isso indica que o modelo possivelmente **\"memorizou\" os dados de treino**, comprometendo a **generaliza√ß√£o**.\n",
        "\n",
        "---\n",
        "\n",
        "### üîç Regress√£o Log√≠stica\n",
        "\n",
        "**Conclus√£o:**\n",
        "> A diferen√ßa entre treino e teste √© **muito menor**, o que indica **boa generaliza√ß√£o**.  \n",
        "A Regress√£o Log√≠stica **n√£o sofre de overfitting severo**.  \n",
        "Entretanto, o **recall moderado** sugere que o modelo ainda **perde quase metade dos clientes que realmente evadem**. Isso pode indicar um poss√≠vel **underfitting da classe minorit√°ria**, sem ser um underfitting generalizado.\n",
        "\n",
        "---\n",
        "\n",
        "## üìå Resumo Geral\n",
        "\n",
        "- **Random Forest**: Apresentou **overfitting** ‚Äî o modelo est√° excessivamente ajustado aos dados de treino.\n",
        "- **Regress√£o Log√≠stica**: Apresentou **consist√™ncia** entre treino e teste. Ainda que o recall seja moderado, **n√£o h√° overfitting severo**. Pode haver uma **dificuldade em capturar a classe minorit√°ria** (churn)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8elJnedNQfcW"
      },
      "source": [
        "# üìã 4 - Interpreta√ß√£o e Conclus√µes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hw7qHk4zQfcW"
      },
      "source": [
        "## 4.1 - Random Forest ‚Äì Import√¢ncia das Vari√°veis\n",
        "\n",
        "Objetivo: entender quais vari√°veis mais impactam a decis√£o do modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTFK1tuAQfcW"
      },
      "outputs": [],
      "source": [
        "importances = modelo_rf.feature_importances_\n",
        "variaveis = X.columns\n",
        "\n",
        "importancia_df = pd.DataFrame({\n",
        "    'Vari√°vel': variaveis,\n",
        "    'Import√¢ncia': importances\n",
        "}).sort_values(by='Import√¢ncia', ascending=False)\n",
        "\n",
        "# Visualizar as 10 vari√°veis mais importantes\n",
        "print(importancia_df.head(10))\n",
        "\n",
        "# Gr√°fico\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(9, 6))\n",
        "sns.barplot(x='Import√¢ncia', y='Vari√°vel', data=importancia_df.head(10))\n",
        "plt.title('Top 10 Vari√°veis mais Importantes - Random Forest')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2L13-V9QfcW"
      },
      "source": [
        "## 4.2 - Regress√£o Log√≠stica ‚Äì Coeficientes das Vari√°veis\n",
        "\n",
        "Objetivo: verificar a influ√™ncia (positiva ou negativa) de cada vari√°vel na evas√£o.\n",
        "\n",
        "Interpreta√ß√£o dos coeficientes:\n",
        "\n",
        "- Coeficiente positivo: aumenta a chance de churn;\n",
        "\n",
        "- Coeficiente negativo: reduz a chance de churn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ssKis6vDQfcX"
      },
      "outputs": [],
      "source": [
        "coeficientes = modelo_log.coef_[0]\n",
        "variaveis_log = Xn_train.columns\n",
        "\n",
        "coef_df = pd.DataFrame({\n",
        "    'Vari√°vel': variaveis_log,\n",
        "    'Coeficiente': coeficientes\n",
        "}).sort_values(by='Coeficiente', key=abs, ascending=False)\n",
        "\n",
        "# Exibir as vari√°veis com maior peso absoluto\n",
        "print(coef_df.head(10))\n",
        "\n",
        "# Gr√°fico\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Coeficiente', y='Vari√°vel', data=coef_df.head(10))\n",
        "plt.title('Top 10 Coeficientes - Regress√£o Log√≠stica')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-37Eo1qQfcX"
      },
      "source": [
        "## 4.3 - An√°lise cr√≠tica dos modelos com refinamentos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gABFad5wQfcY"
      },
      "source": [
        "### 4.3.1 - Revis√£o Cr√≠tica da Modelagem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHrgq6tTQfcY"
      },
      "source": [
        "Com base na Etapa 3, foi poss√≠vel identificar que o modelo de Random Forest apresentava sinais de overfitting e que a Regress√£o Log√≠stica, embora mais est√°vel, ainda poderia melhorar o recall ‚Äî m√©trica cr√≠tica em problemas de churn.\n",
        "\n",
        "Dessa forma, nesta etapa foram aplicadas t√©cnicas de refinamento e ajustes para validar se melhorias nos modelos poderiam gerar ganhos expressivos, sem perder a capacidade de generaliza√ß√£o.\n",
        "\n",
        "As t√©cnicas aplicadas foram:\n",
        "\n",
        "- Ajuste de hiperpar√¢metros com `GridSearchCV` no Random Forest\n",
        "- Regress√£o Log√≠stica com `class_weight='balanced'`\n",
        "- Ajuste do threshold (limiar de classifica√ß√£o) na Regress√£o Log√≠stica"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nobm_Kl4QfcY"
      },
      "source": [
        "### 4.3.2 - Aplica√ß√£o das Melhorias Propostas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfURWN0iQfcY"
      },
      "source": [
        "#### 4.3.2.1 - Ajuste de Hiperpar√¢metros no Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50koMpKNQfcZ"
      },
      "source": [
        "Para mitigar o overfitting observado no Random Forest, foi aplicado um ajuste de hiperpar√¢metros via GridSearchCV, otimizando a m√©trica de F1-score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "CosJkcEpQfcZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9048f4b0-b1d4-4d35-dafb-ed3ec6ec6796"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
            "=== Random Forest com Hiperpar√¢metros Otimizados ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.84      0.89      0.86      1552\n",
            "         1.0       0.64      0.51      0.57       561\n",
            "\n",
            "    accuracy                           0.79      2113\n",
            "   macro avg       0.74      0.70      0.72      2113\n",
            "weighted avg       0.78      0.79      0.79      2113\n",
            "\n",
            "Matriz de Confus√£o:\n",
            "[[1387  165]\n",
            " [ 273  288]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Definir o grid de hiperpar√¢metros\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [5, 10, None],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2],\n",
        "    'max_features': ['sqrt', 'log2']\n",
        "}\n",
        "\n",
        "# Criar e treinar o GridSearchCV\n",
        "grid_rf = GridSearchCV(\n",
        "    estimator=RandomForestClassifier(random_state=42),\n",
        "    param_grid=param_grid,\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    scoring='f1',\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Treinar com os dados\n",
        "grid_rf.fit(X_train, y_train)\n",
        "\n",
        "# Obter o melhor modelo\n",
        "melhor_rf = grid_rf.best_estimator_\n",
        "\n",
        "# Prever no conjunto de teste\n",
        "y_pred_melhor_rf = melhor_rf.predict(X_test)\n",
        "\n",
        "# Exibir relat√≥rio e matriz de confus√£o\n",
        "print(\"=== Random Forest com Hiperpar√¢metros Otimizados ===\")\n",
        "print(classification_report(y_test, y_pred_melhor_rf))\n",
        "print(\"Matriz de Confus√£o:\")\n",
        "print(confusion_matrix(y_test, y_pred_melhor_rf))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWXorSzlQfcZ"
      },
      "source": [
        "#### 4.3.2.2 - Regr. Log√≠stica com class_weight='balanced'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMbeWuHWQfca"
      },
      "source": [
        "Considerando o custo de falsos negativos em churn, foi testado o uso de class_weight='balanced' na Regress√£o Log√≠stica. A estrat√©gia prioriza o aprendizado da classe minorit√°ria, mesmo com propor√ß√£o moderada (26.5%)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "nKx2InjmQfca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1062b8b1-00b1-4703-e622-60d259d84b1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Regress√£o Log√≠stica com class_weight='balanced' ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.91      0.71      0.80      1552\n",
            "         1.0       0.50      0.80      0.61       561\n",
            "\n",
            "    accuracy                           0.73      2113\n",
            "   macro avg       0.70      0.75      0.71      2113\n",
            "weighted avg       0.80      0.73      0.75      2113\n",
            "\n",
            "Matriz de Confus√£o:\n",
            "[[1103  449]\n",
            " [ 113  448]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Treinamento com balanceamento de classes\n",
        "modelo_log_bal = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
        "modelo_log_bal.fit(Xn_train, yn_train)\n",
        "\n",
        "# Previs√£o\n",
        "y_pred_log_bal = modelo_log_bal.predict(Xn_test)\n",
        "\n",
        "# Avalia√ß√£o\n",
        "print(\"=== Regress√£o Log√≠stica com class_weight='balanced' ===\")\n",
        "print(classification_report(yn_test, y_pred_log_bal))\n",
        "print(\"Matriz de Confus√£o:\")\n",
        "print(confusion_matrix(yn_test, y_pred_log_bal))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztW0ZeLaQfca"
      },
      "source": [
        "#### 4.3.2.3 - Ajuste de Threshold com Base na Curva de Precis√£o-Recall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNG7YOjnQfcb"
      },
      "source": [
        "Por fim, foi ajustado o threshold de decis√£o da Regress√£o Log√≠stica tradicional. O objetivo foi encontrar o ponto com melhor F1-score mantendo recall ‚â• 0.65. Essa abordagem visa melhorar a sensibilidade sem comprometer excessivamente a precis√£o."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "AEwJivxWQfcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a8ce005-a114-421a-81fc-7c93f9d3a8af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Regress√£o Log√≠stica com Novo Threshold Otimizado (threshold = 0.31) ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.90      0.76      0.83      1552\n",
            "         1.0       0.54      0.76      0.63       561\n",
            "\n",
            "    accuracy                           0.76      2113\n",
            "   macro avg       0.72      0.76      0.73      2113\n",
            "weighted avg       0.80      0.76      0.78      2113\n",
            "\n",
            "Matriz de Confus√£o:\n",
            "[[1186  366]\n",
            " [ 132  429]]\n"
          ]
        }
      ],
      "source": [
        "# Gerar probabilidades com o modelo de Regress√£o Log√≠stica\n",
        "y_probs = modelo_log.predict_proba(Xn_test)[:, 1]  # Probabilidade da classe 1 (churn)\n",
        "\n",
        "# Obter precis√£o, recall e thresholds da curva\n",
        "prec, rec, thresholds = precision_recall_curve(yn_test, y_probs)\n",
        "\n",
        "# Calcular F1-score para cada ponto da curva\n",
        "f1_scores = 2 * (prec * rec) / (prec + rec + 1e-6)  # evitar divis√£o por zero\n",
        "\n",
        "# Filtrar apenas os thresholds com recall acima de 0.65\n",
        "validos = rec >= 0.65\n",
        "\n",
        "# Selecionar o melhor threshold com base no maior F1-score entre os v√°lidos\n",
        "if np.any(validos):\n",
        "    idx_max_f1 = np.argmax(f1_scores * validos)\n",
        "    threshold_otimizado = thresholds[idx_max_f1]\n",
        "else:\n",
        "    threshold_otimizado = 0.5  # fallback padr√£o\n",
        "\n",
        "# Aplicar novo threshold √†s probabilidades\n",
        "y_pred_threshold = (y_probs >= threshold_otimizado).astype(int)\n",
        "\n",
        "# Avalia√ß√£o\n",
        "print(f\"=== Regress√£o Log√≠stica com Novo Threshold Otimizado (threshold = {threshold_otimizado:.2f}) ===\")\n",
        "print(classification_report(yn_test, y_pred_threshold))\n",
        "print(\"Matriz de Confus√£o:\")\n",
        "print(confusion_matrix(yn_test, y_pred_threshold))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VWsgjmKQfcb"
      },
      "source": [
        "## 4.3 - Comparativo Final dos Modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBb-zCjyQfcc"
      },
      "source": [
        "A seguir, s√£o apresentados os resultados comparativos obtidos com esses aprimoramentos.\n",
        "\n",
        "| Modelo                                 | Acur√°cia | Precis√£o | Recall    | F1-Score  | FN (evadiu, mas n√£o previsto) |\n",
        "| -------------------------------------- | -------- | -------- | --------- | --------- | ----------------------------- |\n",
        "| **Random Forest (original)**           | 0.784    | 0.617    | 0.494     | 0.549     | 284                           |\n",
        "| **Random Forest (ajustado)**           | 0.790    | 0.640    | 0.510     | 0.570     | 273                           |\n",
        "| **Regress√£o Log√≠stica (original)**     | 0.798    | 0.640    | 0.545     | 0.589     | 255                           |\n",
        "| **Regr. Log√≠stica com `balanced`**     | 0.730    | 0.500    | **0.800** | 0.610     | **113**                       |\n",
        "| **Regr. Log√≠stica com threshold 0.31** | 0.760    | 0.540    | 0.765     | **0.630** | 132                           |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9v1er8psQfcc"
      },
      "source": [
        "## 4.4 - Justificativa do Modelo Final Escolhido"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0XszJH7Qfcc"
      },
      "source": [
        "Ap√≥s aplicar t√©cnicas de refinamento, como ajuste de threshold e balanceamento de classes, o modelo que demonstrou o melhor desempenho geral foi a Regress√£o Log√≠stica com threshold ajustado para 0.31.\n",
        "\n",
        "Esse modelo alcan√ßou um F1-score de 0.63, recall de 0.765 e conseguiu reduzir o n√∫mero de clientes evasores n√£o identificados para 132 ‚Äî um dos melhores resultados entre todos os testes realizados.\n",
        "\n",
        "A escolha est√° alinhada com o objetivo principal do projeto: identificar clientes com risco de churn de forma antecipada, sem sacrificar completamente a precis√£o ou a acur√°cia global."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnb-N5R7Qfcc"
      },
      "source": [
        "## 4.5 - Conclus√µes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Dy8KI5hQfcd"
      },
      "source": [
        "üìå Principais fatores associados ao churn\n",
        "Com base nas an√°lises dos modelos Random Forest e Regress√£o Log√≠stica, os fatores mais relevantes foram:\n",
        "\n",
        "üîç Random Forest ‚Äì Vari√°veis com maior import√¢ncia:\n",
        "Charges.Total (gastos totais)\n",
        "\n",
        "Tenure (tempo como cliente)\n",
        "\n",
        "Charges.Monthly e Charges.Daily\n",
        "\n",
        "Tipo de contrato (Contract_Two year, Contract_One year)\n",
        "\n",
        "Forma de pagamento (PaymentMethod_Electronic check)\n",
        "\n",
        "Tipo de internet (InternetService_Fiber optic)\n",
        "\n",
        "Fatura digital (PaperlessBilling_Yes)\n",
        "\n",
        "G√™nero masculino (gender_Male)\n",
        "\n",
        "Essas vari√°veis contribu√≠ram para reduzir a impureza nas √°rvores, influenciando fortemente a classifica√ß√£o.\n",
        "\n",
        "üìà Regress√£o Log√≠stica ‚Äì Interpreta√ß√£o dos coeficientes:\n",
        "Tenure e Contract_Two year: coeficientes negativos ‚Üí reduzem a chance de churn\n",
        "\n",
        "InternetService_Fiber optic, Charges.Total, PaperlessBilling_Yes, PaymentMethod_Electronic check: coeficientes positivos ‚Üí aumentam a chance de churn\n",
        "\n",
        "TechSupport_Yes e PhoneService_Yes: coeficientes negativos ‚Üí indicam reten√ß√£o\n",
        "\n",
        "üß† Conclus√£o T√©cnica\n",
        "Mesmo em sua vers√£o inicial, a Regress√£o Log√≠stica j√° superava o Random Forest em recall e F1-score, mostrando maior capacidade de generaliza√ß√£o. Ap√≥s os refinamentos, ela se consolidou como o modelo mais eficaz para detectar churn com sensibilidade e estabilidade.\n",
        "\n",
        "Ambos os modelos destacaram vari√°veis como tenure, tipo de contrato e gastos acumulados, mas a Regress√£o Log√≠stica ofereceu interpreta√ß√µes mais claras, facilitando decis√µes orientadas por dados.\n",
        "\n",
        "üí° Estrat√©gias de Reten√ß√£o sugeridas\n",
        "Incentivar contratos de longo prazo com benef√≠cios progressivos\n",
        "\n",
        "Monitorar clientes com altos gastos e oferecer suporte proativo\n",
        "\n",
        "Avaliar perfis com fatura digital e d√©bito eletr√¥nico (maior risco)\n",
        "\n",
        "Refor√ßar suporte t√©cnico, especialmente para usu√°rios de fibra √≥tica\n",
        "\n",
        "Criar campanhas de fideliza√ß√£o para clientes com menos de 6 meses de casa\n",
        "\n",
        "‚úÖ Encerramento\n",
        "O projeto foi conclu√≠do com sucesso, integrando t√©cnicas de pr√©-processamento, modelagem supervisionada e an√°lise interpretativa. Os resultados obtidos oferecem √† empresa uma base s√≥lida para reduzir churn de forma estrat√©gica e orientada por dados."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}